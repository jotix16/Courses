1) The cost function for (lambda=0, nr epochs=40, nr batch=100, eta=0.1) is:
    "acc_train"    "acc_valid"    "acc_test"
    "0.439"        "0.2764"       "0.2735"
    


2) The cost function for (lambda=0, nr epochs=40, nr batch=100, eta=0.001) is:
    "acc_train"    "acc_valid"    "acc_test"
    "0.4548"       "0.3864"       "0.3895" 
    "0.4531"       "0.3828"       "0.3858" <--- no mixing before each epoch	


3) The cost function for (lambda=0.1, nr epochs=40, nr batch=100, eta=0.001) is:
    "acc_train"    "acc_valid"    "acc_test"
    "0.4478"       "0.3895"       "0.3961"  
    "0.4469"       "0.3867"       "0.3917" <--- no mixing before each epoch	

4) The cost function for (lambda=1, nr epochs=40, nr batch=100, eta=0.001) is:
    "acc_train"    "acc_valid"    "acc_test"
    "0.3974"       "0.3625"       "0.3755"  


Improvements
A]
	0) Mixing before each epoch-------
	1) More Dat (biggest improvement)------ 
	The cost function for (lambda=0.1, nr epochs=40, nr batch=100, eta=0.001) is:
	    "acc_train"    "acc_valid"    "acc_test"
	    "0.42247"      "0.409"        "0.4122"


	2) Grid Search---------
	    batchnr = 50:10:100
	    lambdas = 0.1:0.1:0.6;
	    etas = .001:.001:0.01;
			
	    max_val_acc = 0.407
	    max_eta_lambda=[0.1 ,0.002]
	    The cost function for (lambda=0.1, nr epochs=40, nr batch=80, eta=0.002) is:
		"acc_train"    "acc_valid"    "acc_test"
		"0.4228"       "0.409"        "0.4081" 

	3) Ensamble (5 NNs)-----------
	The cost function for 5NN ensamble trained with (lambda=0.1, nr epochs=40, nr batch=100, eta=0.001) is:
	    "acc_test"
	    "0.4111"


B] SVM multi-class loss

1) The cost function for (lambda=0, nr epochs=40, nr batch=100, eta=0.1) is:
  *) Cross entropy loss function
    "acc_train"    "acc_valid"    "acc_test"
    "0.3819"       "0.2536"       "0.2496"  
  *) SVM loss function
    "acc_train"    "acc_valid"    "acc_test"
    "0.2808"       "0.1721"       "0.1713"  



2) The cost function for (lambda=0, nr epochs=40, nr batch=100, eta=0.001) is:
  *) Cross entropy loss function
    "acc_train"    "acc_valid"    "acc_test"
    "0.4576"       "0.3802"       "0.3903"  
  *) SVM loss function
    "acc_train"    "acc_valid"    "acc_test"
    "0.4259"       "0.3456"       "0.3435"

3)The cost function for (lambda=0.1, nr epochs=40, nr batch=100, eta=0.001) is:
  *) Cross entropy loss function
    "acc_train"    "acc_valid"    "acc_test"
    "0.4459"       "0.3893"       "0.3962"  
  *) SVM loss function
    "acc_train"    "acc_valid"    "acc_test"
    "0.4333"       "0.3568"       "0.3522" 


4)The cost function for (lambda=1, nr epochs=40, nr batch=100, eta=0.001) is:
  *) Cross entropy loss function
    "acc_train"    "acc_valid"    "acc_test"
    "0.3962"       "0.3668"       "0.3738"  
  *) SVM loss functin
    "acc_train"    "acc_valid"    "acc_test"
    "0.4011"       "0.367"        "0.362"

5)Full Data scenario
The cost function for (lambda=0.1, nr epochs=100, nr batch=100, eta=0.001) is:
  *) Cross entropy loss function
    "acc_train"    "acc_valid"    "acc_test"
    "0.423"        "0.402"        "0.4114"  
  *) SVM loss functin
    "acc_train"    "acc_valid"    "acc_test"
    "0.33257"      "0.326"        "0.3099" 

6) Decayed Learning Rate
The cost function for (lambda=0.1, nr epochs=100, nr batch=100, eta=0.00012158) is:
    "acc_train"    "acc_valid"    "acc_test"
    "0.42433"      "0.406"        "0.4104"  

    "acc_train"    "acc_valid"    "acc_test"
    "0.41441"      "0.399"        "0.3897"  

