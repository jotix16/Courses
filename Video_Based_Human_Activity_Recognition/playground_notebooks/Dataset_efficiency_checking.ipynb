{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('.')\n",
    "#from config import Config\n",
    "\n",
    "from config import Config\n",
    "from data_utils import video_to_frames\n",
    "from data_utils import metadata_loader\n",
    "from data_utils import dataset_builder\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding videos to frames.\n",
      "./data/20bn-something-something-v2-video\n",
      "Generating training files.\n",
      "Deleted folders: 0\n",
      "./data/20bn-something-something-v2-label\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# hyperparams\n",
    "config = Config()\n",
    "\n",
    "# Decode videos\n",
    "video_to_frames.decode_videos(config)\n",
    "\n",
    "# Get metadata\n",
    "ml = metadata_loader.MetadataLoader(config)\n",
    "metadata = ml.load_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "db = dataset_builder.DatasetBuilder(config)\n",
    "train_dataset = db.make_frame_dataset(metadata['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85, 200, 120, 3) (85, 174)\n",
      "(85, 200, 120, 3) (85, 174)\n",
      "(85, 200, 120, 3) (85, 174)\n",
      "(85, 200, 120, 3) (85, 174)\n",
      "(85, 200, 120, 3) (85, 174)\n",
      "(85, 200, 120, 3) (85, 174)\n",
      "(85, 200, 120, 3) (85, 174)\n",
      "(85, 200, 120, 3) (85, 174)\n",
      "(85, 200, 120, 3) (85, 174)\n",
      "(85, 200, 120, 3) (85, 174)\n",
      "\n",
      "time required for frame dataset: 33.84043741226196\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for x, y in train_dataset.batch(85).take(10):\n",
    "    print(x.shape,y.shape)\n",
    "    \n",
    "print(\"\\ntime required for frame dataset:\",time.time()-start)\n",
    "\n",
    "x,y = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "db2 = dataset_builder.DatasetBuilder(config)\n",
    "train_dataset2 = db2.make_video_dataset(metadata['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 85, 200, 120, 3) (1, 174)\n",
      "(1, 85, 200, 120, 3) (1, 174)\n",
      "(1, 85, 200, 120, 3) (1, 174)\n",
      "(1, 85, 200, 120, 3) (1, 174)\n",
      "(1, 85, 200, 120, 3) (1, 174)\n",
      "(1, 85, 200, 120, 3) (1, 174)\n",
      "(1, 85, 200, 120, 3) (1, 174)\n",
      "(1, 85, 200, 120, 3) (1, 174)\n",
      "(1, 85, 200, 120, 3) (1, 174)\n",
      "(1, 85, 200, 120, 3) (1, 174)\n",
      "\n",
      "time required for video dataset: 0.9109525680541992\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for x, y in train_dataset2.batch(1).take(10):\n",
    "    print(x.shape,y.shape)\n",
    "print(\"\\ntime required for video dataset:\", time.time()-start)\n",
    "x,y = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datagen = ImageDataGenerator()\n",
    "\n",
    "target_size=(config.img_height,config.img_width)\n",
    "train_it = datagen.flow_from_directory(config.frame_path,target_size=target_size, class_mode='binary', batch_size=85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85, 120, 200, 3)\n",
      "(85, 120, 200, 3)\n",
      "(85, 120, 200, 3)\n",
      "(85, 120, 200, 3)\n",
      "(85, 120, 200, 3)\n",
      "(85, 120, 200, 3)\n",
      "(85, 120, 200, 3)\n",
      "(85, 120, 200, 3)\n",
      "(85, 120, 200, 3)\n",
      "(85, 120, 200, 3)\n",
      "(85, 120, 200, 3)\n",
      "time required for KERAS frame dataset: 1.673015832901001\n"
     ]
    }
   ],
   "source": [
    "nr = 0\n",
    "start = time.time()\n",
    "for i in train_it:\n",
    "    if nr >10: break\n",
    "    print(i[0].shape)\n",
    "    nr+=1\n",
    "print(\"time required for KERAS frame dataset:\", time.time()-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}