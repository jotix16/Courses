{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa.display as disp\n",
    "import numpy as np\n",
    "\n",
    "from data_utils.data_loader import Data_loader, EMO_DICT\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Dataflair reproduce (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dl= Data_loader()\n",
    "data = dl.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load only samples only express 'calm', 'happy', 'fearful' or 'disgust'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "observed_emotions=['calm', 'happy', 'fearful', 'disgust']\n",
    "N_observed = 4\n",
    "EMO_DICT= {0:'neutral', 1:'calm', 2:'happy', 3:'sad', 4:'angry', 5:'fearful', 6:'disgust', 7:'surprised'}\n",
    "NR_TO_NR = {1:0, 2:1, 5:2, 6:3}\n",
    "x = []\n",
    "y = []\n",
    "for d in data:\n",
    "    emot_nr = np.argmax(d['emotion'])\n",
    "    if EMO_DICT[emot_nr] in observed_emotions:\n",
    "        x.append(np.hstack((np.mean(d['mfcc'],axis=0), np.mean(d['chroma'],axis=0), np.mean(d['mel'],axis=0))))\n",
    "        \n",
    "        y.append(np.eye(N_observed, dtype=np.int32)[NR_TO_NR[emot_nr]-1])\n",
    "    \n",
    "    \n",
    "    \n",
    "# splitt for train\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 300)               54300     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 1204      \n",
      "=================================================================\n",
      "Total params: 55,504\n",
      "Trainable params: 55,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_keras = tf.keras.Sequential([layers.Dense(300,input_shape=[len(X_train[0])], kernel_initializer=\"he_normal\", activation=\"relu\") \n",
    "                             ,layers.Dense(4,activation='softmax')])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.003, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.1)\n",
    "model_keras.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "        \n",
    "model_keras.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = model_keras.fit(np.array(X_train),np.array(y_train),batch_size=256, epochs=300,shuffle=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7621 - accuracy: 0.7792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7620943188667297, 0.7792207598686218]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_keras.evaluate(np.array(X_test),np.array(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size=256, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(300,), learning_rate='adaptive',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.18%\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "\n",
    "#DataFlair - Calculate the accuracy of our model\n",
    "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "#DataFlair - Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.2)\n",
    "\n",
    "X_train = np.expand_dims(np.array(X_train), axis=2)\n",
    "X_test = np.expand_dims(np.array(X_test), axis=2)\n",
    "\n",
    "y_train, y_test = np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "#X_train = np.expand_dims(np.array(X_train), axis=2)\n",
    "#X_test = np.expand_dims(np.array(X_test), axis=2)\n",
    "\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 180, 1)\n",
      "(154, 180, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "C1 (Conv1D)                  (None, 180, 256)          2304      \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 180, 256)          0         \n",
      "_________________________________________________________________\n",
      "C2 (Conv1D)                  (None, 180, 256)          524544    \n",
      "_________________________________________________________________\n",
      "activation_170 (Activation)  (None, 180, 256)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 180, 256)          1024      \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 180, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "C3 (Conv1D)                  (None, 22, 128)           262272    \n",
      "_________________________________________________________________\n",
      "activation_171 (Activation)  (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "C4 (Conv1D)                  (None, 22, 128)           131200    \n",
      "_________________________________________________________________\n",
      "activation_172 (Activation)  (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "C5 (Conv1D)                  (None, 22, 128)           131200    \n",
      "_________________________________________________________________\n",
      "activation_173 (Activation)  (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "C6 (Conv1D)                  (None, 22, 128)           131200    \n",
      "_________________________________________________________________\n",
      "activation_174 (Activation)  (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 22, 128)           512       \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "C7 (Conv1D)                  (None, 2, 64)             65600     \n",
      "_________________________________________________________________\n",
      "activation_175 (Activation)  (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "C8 (Conv1D)                  (None, 2, 64)             32832     \n",
      "_________________________________________________________________\n",
      "activation_176 (Activation)  (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "OUT (Dense)                  (None, 4)                 516       \n",
      "_________________________________________________________________\n",
      "activation_177 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 1,283,204\n",
      "Trainable params: 1,282,436\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# New model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Conv1D(256, 8, padding='same',input_shape=(X_train.shape[1],1), name=\"C1\"))  # X_train.shape[1] = No. of Columns\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Conv1D(256, 8, padding='same', name=\"C2\"))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.MaxPooling1D(pool_size=(8)))\n",
    "\n",
    "for i in range(3):\n",
    "    model.add(layers.Conv1D(128, 8, padding='same', name=\"C\"+str(i+3)))\n",
    "    model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Conv1D(128, 8, padding='same', name=\"C6\"))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.MaxPooling1D(pool_size=(8)))\n",
    "\n",
    "model.add(layers.Conv1D(64, 8, padding='same', name=\"C7\"))\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Conv1D(64, 8, padding='same', name=\"C8\"))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(4, name=\"OUT\")) # Target class number\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "39/39 [==============================] - 6s 161ms/step - loss: 1.4931 - accuracy: 0.2590 - val_loss: 1.3861 - val_accuracy: 0.2597\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 6s 156ms/step - loss: 1.3765 - accuracy: 0.2752 - val_loss: 1.3860 - val_accuracy: 0.2597\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 6s 167ms/step - loss: 1.3031 - accuracy: 0.3811 - val_loss: 1.3860 - val_accuracy: 0.2532\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 6s 165ms/step - loss: 1.2675 - accuracy: 0.4218 - val_loss: 1.3858 - val_accuracy: 0.2597\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 6s 162ms/step - loss: 1.2274 - accuracy: 0.4707 - val_loss: 1.3855 - val_accuracy: 0.2727\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 7s 168ms/step - loss: 1.2246 - accuracy: 0.4756 - val_loss: 1.3842 - val_accuracy: 0.2987\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 7s 176ms/step - loss: 1.1878 - accuracy: 0.5293 - val_loss: 1.3820 - val_accuracy: 0.2987\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 7s 175ms/step - loss: 1.1613 - accuracy: 0.5212 - val_loss: 1.3783 - val_accuracy: 0.3117\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 7s 173ms/step - loss: 1.1506 - accuracy: 0.5570 - val_loss: 1.3730 - val_accuracy: 0.3117\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 7s 172ms/step - loss: 1.1245 - accuracy: 0.5651 - val_loss: 1.3619 - val_accuracy: 0.3442\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 7s 169ms/step - loss: 1.0963 - accuracy: 0.6156 - val_loss: 1.3488 - val_accuracy: 0.3571\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 7s 174ms/step - loss: 1.0787 - accuracy: 0.5993 - val_loss: 1.3313 - val_accuracy: 0.3766\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 7s 175ms/step - loss: 1.0592 - accuracy: 0.6059 - val_loss: 1.3076 - val_accuracy: 0.3896\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 7s 175ms/step - loss: 1.0334 - accuracy: 0.6368 - val_loss: 1.2821 - val_accuracy: 0.4416\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 7s 170ms/step - loss: 1.0185 - accuracy: 0.6368 - val_loss: 1.2501 - val_accuracy: 0.4805\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 7s 169ms/step - loss: 0.9902 - accuracy: 0.6433 - val_loss: 1.2207 - val_accuracy: 0.4805\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 6s 166ms/step - loss: 0.9653 - accuracy: 0.6661 - val_loss: 1.1965 - val_accuracy: 0.5130\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 7s 170ms/step - loss: 0.9498 - accuracy: 0.6678 - val_loss: 1.1707 - val_accuracy: 0.5065\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 7s 169ms/step - loss: 0.9420 - accuracy: 0.6661 - val_loss: 1.1443 - val_accuracy: 0.5065\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 7s 168ms/step - loss: 0.9136 - accuracy: 0.6726 - val_loss: 1.1253 - val_accuracy: 0.5260\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 7s 181ms/step - loss: 0.8659 - accuracy: 0.7134 - val_loss: 1.1237 - val_accuracy: 0.5519\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 7s 172ms/step - loss: 0.8575 - accuracy: 0.7166 - val_loss: 1.1003 - val_accuracy: 0.5195\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 7s 171ms/step - loss: 0.8593 - accuracy: 0.7101 - val_loss: 1.0873 - val_accuracy: 0.5325\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 7s 170ms/step - loss: 0.8257 - accuracy: 0.7296 - val_loss: 1.0672 - val_accuracy: 0.5325\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 7s 170ms/step - loss: 0.7939 - accuracy: 0.7541 - val_loss: 1.0551 - val_accuracy: 0.5584\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 7s 173ms/step - loss: 0.7884 - accuracy: 0.7606 - val_loss: 1.0376 - val_accuracy: 0.5455\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 7s 171ms/step - loss: 0.7822 - accuracy: 0.7573 - val_loss: 1.0290 - val_accuracy: 0.5519\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 7s 173ms/step - loss: 0.7375 - accuracy: 0.7655 - val_loss: 1.0269 - val_accuracy: 0.5584\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 7s 173ms/step - loss: 0.7404 - accuracy: 0.7769 - val_loss: 1.0176 - val_accuracy: 0.5649\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 7s 179ms/step - loss: 0.7104 - accuracy: 0.7736 - val_loss: 1.0317 - val_accuracy: 0.5325\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 7s 176ms/step - loss: 0.6997 - accuracy: 0.7850 - val_loss: 1.0123 - val_accuracy: 0.5714\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 7s 177ms/step - loss: 0.6984 - accuracy: 0.7948 - val_loss: 1.0202 - val_accuracy: 0.5519\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 7s 174ms/step - loss: 0.6622 - accuracy: 0.7948 - val_loss: 0.9893 - val_accuracy: 0.5779\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 7s 174ms/step - loss: 0.6495 - accuracy: 0.7883 - val_loss: 0.9820 - val_accuracy: 0.5844\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 7s 182ms/step - loss: 0.6133 - accuracy: 0.8257 - val_loss: 0.9763 - val_accuracy: 0.5779\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 7s 176ms/step - loss: 0.6216 - accuracy: 0.7801 - val_loss: 0.9579 - val_accuracy: 0.5974\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 7s 182ms/step - loss: 0.6060 - accuracy: 0.8208 - val_loss: 0.9495 - val_accuracy: 0.6104\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 8s 197ms/step - loss: 0.5727 - accuracy: 0.8274 - val_loss: 0.9460 - val_accuracy: 0.6039\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 7s 190ms/step - loss: 0.5481 - accuracy: 0.8502 - val_loss: 0.9358 - val_accuracy: 0.6039\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 7s 183ms/step - loss: 0.5498 - accuracy: 0.8290 - val_loss: 0.9479 - val_accuracy: 0.5909\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 8s 203ms/step - loss: 0.5516 - accuracy: 0.8322 - val_loss: 0.9348 - val_accuracy: 0.6169\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 7s 190ms/step - loss: 0.5089 - accuracy: 0.8550 - val_loss: 0.9274 - val_accuracy: 0.6364\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 7s 173ms/step - loss: 0.5191 - accuracy: 0.8567 - val_loss: 0.9515 - val_accuracy: 0.5844\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 7s 184ms/step - loss: 0.4897 - accuracy: 0.8648 - val_loss: 0.9070 - val_accuracy: 0.5974\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 7s 173ms/step - loss: 0.4628 - accuracy: 0.8909 - val_loss: 0.8917 - val_accuracy: 0.6494\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 7s 177ms/step - loss: 0.4675 - accuracy: 0.8730 - val_loss: 0.9276 - val_accuracy: 0.5974\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 7s 187ms/step - loss: 0.4420 - accuracy: 0.9023 - val_loss: 0.8947 - val_accuracy: 0.6234\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 7s 178ms/step - loss: 0.4312 - accuracy: 0.8909 - val_loss: 0.8866 - val_accuracy: 0.6299\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 7s 173ms/step - loss: 0.4144 - accuracy: 0.8990 - val_loss: 0.8969 - val_accuracy: 0.6364\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 7s 180ms/step - loss: 0.3759 - accuracy: 0.9202 - val_loss: 0.8746 - val_accuracy: 0.6169\n"
     ]
    }
   ],
   "source": [
    "# opt = tf.keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "# opt = tf.keras.optimizers.Adam(lr=0.0001)\n",
    "opt = tf.keras.optimizers.RMSprop(lr=0.00001, decay=1e-6)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_history=model.fit(X_train, y_train, batch_size=16, epochs=50, validation_data=(X_test, y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) RNN/LSTM/GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load only samples only express 'calm', 'happy', 'fearful' or 'disgust'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_emotions=['calm', 'happy', 'fearful', 'disgust']\n",
    "N_observed = 4\n",
    "EMO_DICT= {0:'neutral', 1:'calm', 2:'happy', 3:'sad', 4:'angry', 5:'fearful', 6:'disgust', 7:'surprised'}\n",
    "NR_TO_NR = {1:0, 2:1, 5:2, 6:3}\n",
    "x = []\n",
    "y = []\n",
    "for d in data:\n",
    "    emot_nr = np.argmax(d['emotion'])\n",
    "    if EMO_DICT[emot_nr] in observed_emotions:      \n",
    "        x.append(np.hstack((d['mfcc'], d['chroma'], d['mel'])))\n",
    "        \n",
    "        y.append(np.eye(N_observed, dtype=np.int32)[NR_TO_NR[emot_nr]-1])\n",
    "    \n",
    "# splitt for train\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform lists to numpy arrays\n",
    "X_train, X_test, y_train, y_test = np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test)\n",
    "\n",
    "# pad\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test,X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxdox/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 165, 180) (154, 165, 180) (614, 4) (154, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxdox/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n",
      "/home/maxdox/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train = np.nan_to_num((X_train - mean)/std, nan=0.0)\n",
    "X_test = np.nan_to_num((X_test - mean)/std, nan=0.0)\n",
    "# X_test = (X_test - mean)/std\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_12 (LSTM)               (None, 300)               577200    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                19264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 596,980\n",
      "Trainable params: 596,852\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Add a LSTM layer with 300 internal units.\n",
    "model.add( tf.keras.layers.LSTM(300, input_shape=(None, X_train.shape[2])))\n",
    "\n",
    "# Add a Dense layer with 64 units.\n",
    "model.add(layers.Dense(64, kernel_initializer=\"he_normal\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr=0.003, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.1)\n",
    "#opt = tf.keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 1.3817 - accuracy: 0.4137 - val_loss: nan - val_accuracy: 0.3961\n",
      "Epoch 2/25\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 0.9816 - accuracy: 0.5831 - val_loss: nan - val_accuracy: 0.4481\n",
      "Epoch 3/25\n",
      "39/39 [==============================] - 13s 328ms/step - loss: 0.8549 - accuracy: 0.6368 - val_loss: nan - val_accuracy: 0.5325\n",
      "Epoch 4/25\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 0.7527 - accuracy: 0.7182 - val_loss: nan - val_accuracy: 0.5714\n",
      "Epoch 5/25\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 0.6368 - accuracy: 0.7638 - val_loss: nan - val_accuracy: 0.5779\n",
      "Epoch 6/25\n",
      "39/39 [==============================] - 13s 327ms/step - loss: 0.5660 - accuracy: 0.8013 - val_loss: nan - val_accuracy: 0.5714\n",
      "Epoch 7/25\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 0.4888 - accuracy: 0.8322 - val_loss: nan - val_accuracy: 0.6234\n",
      "Epoch 8/25\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 0.4090 - accuracy: 0.8664 - val_loss: nan - val_accuracy: 0.5844\n",
      "Epoch 9/25\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 0.3732 - accuracy: 0.8827 - val_loss: nan - val_accuracy: 0.6039\n",
      "Epoch 10/25\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 0.3132 - accuracy: 0.8974 - val_loss: nan - val_accuracy: 0.6039\n",
      "Epoch 11/25\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 0.2990 - accuracy: 0.9121 - val_loss: nan - val_accuracy: 0.6039\n",
      "Epoch 12/25\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 0.2346 - accuracy: 0.9349 - val_loss: nan - val_accuracy: 0.6429\n",
      "Epoch 13/25\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 0.2301 - accuracy: 0.9365 - val_loss: nan - val_accuracy: 0.6364\n",
      "Epoch 14/25\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 0.2003 - accuracy: 0.9479 - val_loss: nan - val_accuracy: 0.6558\n",
      "Epoch 15/25\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 0.1619 - accuracy: 0.9593 - val_loss: nan - val_accuracy: 0.6429\n",
      "Epoch 16/25\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 0.1342 - accuracy: 0.9788 - val_loss: nan - val_accuracy: 0.6494\n",
      "Epoch 17/25\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 0.1329 - accuracy: 0.9642 - val_loss: nan - val_accuracy: 0.6299\n",
      "Epoch 18/25\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 0.1199 - accuracy: 0.9756 - val_loss: nan - val_accuracy: 0.6364\n",
      "Epoch 19/25\n",
      "39/39 [==============================] - 13s 322ms/step - loss: 0.1136 - accuracy: 0.9788 - val_loss: nan - val_accuracy: 0.6039\n",
      "Epoch 20/25\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 0.1165 - accuracy: 0.9723 - val_loss: nan - val_accuracy: 0.6299\n",
      "Epoch 21/25\n",
      "39/39 [==============================] - 13s 330ms/step - loss: 0.0960 - accuracy: 0.9837 - val_loss: nan - val_accuracy: 0.6429\n",
      "Epoch 22/25\n",
      "39/39 [==============================] - 13s 325ms/step - loss: 0.1010 - accuracy: 0.9805 - val_loss: nan - val_accuracy: 0.6623\n",
      "Epoch 23/25\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 0.0819 - accuracy: 0.9837 - val_loss: nan - val_accuracy: 0.6494\n",
      "Epoch 24/25\n",
      "39/39 [==============================] - 13s 323ms/step - loss: 0.0805 - accuracy: 0.9919 - val_loss: nan - val_accuracy: 0.6494\n",
      "Epoch 25/25\n",
      "39/39 [==============================] - 13s 321ms/step - loss: 0.0706 - accuracy: 0.9870 - val_loss: nan - val_accuracy: 0.6494\n"
     ]
    }
   ],
   "source": [
    "_=model.fit(X_train, y_train, batch_size=16, epochs=25, validation_data=(X_test, y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 128ms/step - loss: nan - accuracy: 0.6494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.649350643157959]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kfold Cross Validation\n",
    "### Use either the data from CNN to prepare, or use the data from LSTM from previos sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv1D(256, 8, padding='same',input_shape=(inputs[train].shape[1],1), name=\"C1\"))  \n",
    "    model.add(layers.Activation('relu'))\n",
    "\n",
    "    model.add(layers.Conv1D(256, 8, padding='same', name=\"C2\"))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.MaxPooling1D(pool_size=(8)))\n",
    "\n",
    "    for i in range(3):\n",
    "        model.add(layers.Conv1D(128, 8, padding='same', name=\"C\"+str(i+3)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "\n",
    "    model.add(layers.Conv1D(128, 8, padding='same', name=\"C6\"))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.MaxPooling1D(pool_size=(8)))\n",
    "\n",
    "    model.add(layers.Conv1D(64, 8, padding='same', name=\"C7\"))\n",
    "    model.add(layers.Activation('relu'))\n",
    "\n",
    "    model.add(layers.Conv1D(64, 8, padding='same', name=\"C8\"))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(4, name=\"OUT\")) # Target class number\n",
    "    model.add(layers.Activation('softmax'))\n",
    "\n",
    "    # compile model\n",
    "    opt = tf.keras.optimizers.RMSprop(lr=0.00001, decay=1e-6)\n",
    "    model.compile(optimizer=opt,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model():\n",
    "  model = tf.keras.Sequential()\n",
    "\n",
    "  # Add a LSTM layer with 300 internal units.\n",
    "  model.add( tf.keras.layers.LSTM(300, input_shape=(None, 180)))\n",
    "\n",
    "  # Add a Dense layer with 64 units.\n",
    "  model.add(layers.Dense(64, kernel_initializer=\"he_normal\"))\n",
    "  model.add(layers.BatchNormalization())\n",
    "\n",
    "  model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "  opt = tf.keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0, amsgrad=False, clipnorm=1.)\n",
    " \n",
    "  model.compile(loss='categorical_crossentropy', \n",
    "                optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.concatenate((X_train,X_test))\n",
    "targets = np.concatenate((y_train,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed =7\n",
    "np.random.seed(seed)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "TimeSeriesSplit(max_train_size=None, n_splits=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kfold for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "------------------------------------------------------------------------\nTraining for fold 1 \nScore for fold 1: loss of 1.2654606103897095; accuracy of 46.75324559211731%\n------------------------------------------------------------------------\nTraining for fold 2 \nScore for fold 2: loss of 1.1848477125167847; accuracy of 57.14285969734192%\n------------------------------------------------------------------------\nTraining for fold 3 \nScore for fold 3: loss of 1.2830265760421753; accuracy of 48.051947355270386%\n------------------------------------------------------------------------\nTraining for fold 4 \nScore for fold 4: loss of 1.2638294696807861; accuracy of 45.45454680919647%\n------------------------------------------------------------------------\nTraining for fold 5 \nScore for fold 5: loss of 1.262800693511963; accuracy of 50.64935088157654%\n------------------------------------------------------------------------\nTraining for fold 6 \nScore for fold 6: loss of 1.2728854417800903; accuracy of 44.155845046043396%\n------------------------------------------------------------------------\nTraining for fold 7 \nScore for fold 7: loss of 1.2523367404937744; accuracy of 50.64935088157654%\n------------------------------------------------------------------------\nTraining for fold 8 \nScore for fold 8: loss of 1.2661043405532837; accuracy of 42.85714328289032%\n------------------------------------------------------------------------\nTraining for fold 9 \nScore for fold 9: loss of 1.2683889865875244; accuracy of 53.94737124443054%\n------------------------------------------------------------------------\nTraining for fold 10 \nScore for fold 10: loss of 1.2383432388305664; accuracy of 47.36842215061188%\n"
    }
   ],
   "source": [
    "\n",
    "CV_scores = []\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no =1\n",
    "for train, test in kfold.split(x,y):\n",
    "    model = get_model()\n",
    "    \n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ')\n",
    "    model_history=model.fit(inputs[train], targets[train], batch_size=10, epochs=150, verbose=0, validation_split=0.15)\n",
    "    \n",
    "    #evaluate model\n",
    "    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    fold_no+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Kfold average:\n loss: 1.2558023810386658 \n accuracy: 48.70300829410553\n"
    }
   ],
   "source": [
    "av_loss = np.mean(loss_per_fold)\n",
    "av_acc = np.mean(acc_per_fold) \n",
    "print(\"Kfold average:\\n loss:\", av_loss, \"\\n accuracy:\", av_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_scores = []\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no =1\n",
    "plt.figure(figsize=(20,10))\n",
    "for train, test in tscv.split(x,y):\n",
    "    \n",
    "    model = LSTM_model()\n",
    "    \n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ')\n",
    "    model_history=model.fit(inputs[train], targets[train], batch_size=16, epochs=30)\n",
    "\n",
    "    # plot\n",
    "    plt.subplot(121)\n",
    "    plt.plot(model_history.history['loss'],label=\"training data, fold:\" +str(fold_no))\n",
    "    plt.grid()\n",
    "    plt.subplot(122)\n",
    "    plt.plot(model_history.history['accuracy'],label=\"training data, fold:\" +str(fold_no))\n",
    "    plt.grid()\n",
    "    \n",
    "\n",
    "    #evaluate model\n",
    "    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    fold_no+=1\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "av_loss = np.mean(loss_per_fold)\n",
    "av_acc = np.mean(acc_per_fold) \n",
    "print(\"Kfold average:\\n loss:\", av_loss, \"\\n accuracy:\", av_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}